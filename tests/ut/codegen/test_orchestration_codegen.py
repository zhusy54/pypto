# Copyright (c) PyPTO Contributors.
# This program is free software, you can redistribute it and/or modify it under the terms and conditions of
# CANN Open Software License Agreement Version 2.0 (the "License").
# Please refer to the License for details. You may not use this file except in compliance with the License.
# THIS SOFTWARE IS PROVIDED ON AN "AS IS" BASIS, WITHOUT WARRANTIES OF ANY KIND, EITHER EXPRESS OR IMPLIED,
# INCLUDING BUT NOT LIMITED TO NON-INFRINGEMENT, MERCHANTABILITY, OR FITNESS FOR A PARTICULAR PURPOSE.
# See LICENSE in the root of the software repository for the full text of the License.
# -----------------------------------------------------------------------------------------------------------

"""Unit tests for orchestration code generation, including tuple return value handling."""

import difflib
import textwrap

import pypto.language as pl
import pytest
from pypto import backend, codegen
from pypto.backend import BackendType


def assert_code_equal(actual: str, expected: str) -> None:
    """Compare generated code against expected output, with unified diff on failure."""
    actual_stripped = actual.strip()
    expected_stripped = textwrap.dedent(expected).strip()
    if actual_stripped != expected_stripped:
        diff = "\n".join(
            difflib.unified_diff(
                expected_stripped.splitlines(),
                actual_stripped.splitlines(),
                fromfile="expected",
                tofile="actual",
                lineterm="",
            )
        )
        raise AssertionError(f"Code mismatch:\n{diff}")


class TestOrchestration:
    """Test orchestration codegen format."""

    def test_basic_structure(self):
        """Test codegen produces PTO2 format: make_tensor_external, PTOParam, pto2_rt_submit_task."""
        backend.reset_for_testing()
        backend.set_backend_type(BackendType.CCE)

        @pl.program
        class BasicProgram:
            @pl.function(type=pl.FunctionType.InCore)
            def kernel_add(
                self,
                a: pl.Tensor[[16, 16], pl.FP32],
                b: pl.Tensor[[16, 16], pl.FP32],
                output: pl.Out[pl.Tensor[[16, 16], pl.FP32]],
            ) -> pl.Tensor[[16, 16], pl.FP32]:
                a_tile: pl.Tile[[16, 16], pl.FP32] = pl.load(a, [0, 0], [16, 16])
                b_tile: pl.Tile[[16, 16], pl.FP32] = pl.load(b, [0, 0], [16, 16])
                result: pl.Tile[[16, 16], pl.FP32] = pl.add(a_tile, b_tile)
                out: pl.Tensor[[16, 16], pl.FP32] = pl.store(result, [0, 0], [16, 16], output)
                return out

            @pl.function(type=pl.FunctionType.Orchestration)
            def orch_basic(
                self,
                a: pl.Tensor[[16, 16], pl.FP32],
                b: pl.Tensor[[16, 16], pl.FP32],
            ) -> pl.Tensor[[16, 16], pl.FP32]:
                c: pl.Tensor[[16, 16], pl.FP32] = pl.create_tensor([16, 16], dtype=pl.FP32)
                c = self.kernel_add(a, b, c)
                d: pl.Tensor[[16, 16], pl.FP32] = pl.create_tensor([16, 16], dtype=pl.FP32)
                d = self.kernel_add(c, b, d)
                return d

        generator = codegen.CCECodegen()
        files = generator.generate(BasicProgram)
        code = files["orchestration/orch_basic.cpp"]

        expected = """\
            // Orchestration Function: orch_basic
            // Generated by PyPTO IR Compiler

            #include <stddef.h>
            #include <stdint.h>
            #include <stdio.h>

            #include "pto_orchestration_api.h"

            #define ARG_PTR_A 0
            #define ARG_PTR_B 1
            #define ARG_PTR_D 2

            // Helper to encode float as uint64_t for scalar params
            static uint64_t float_to_u64(float f) {
                union {
                    float f32;
                    uint64_t u64;
                } conv;
                conv.u64 = 0;  // Clear upper bits
                conv.f32 = f;
                return conv.u64;
            }

            extern "C" {

            __attribute__((visibility("default")))
            PTO2OrchestrationConfig aicpu_orchestration_config(uint64_t* args, int arg_count) {
                (void)args;
                (void)arg_count;
                return PTO2OrchestrationConfig{
                    .expected_arg_count = 3,
                };
            }

            __attribute__((visibility("default")))
            void aicpu_orchestration_entry(PTO2Runtime* rt, uint64_t* args, int arg_count) {
                (void)arg_count;

                // Extract device pointers
                void* arg_a_ptr = reinterpret_cast<void*>(args[ARG_PTR_A]);
                void* arg_b_ptr = reinterpret_cast<void*>(args[ARG_PTR_B]);
                void* arg_d_ptr = reinterpret_cast<void*>(args[ARG_PTR_D]);

                // External tensors
                uint64_t a_shapes[2] = {16, 16};
                Tensor ext_a = make_tensor_external(arg_a_ptr, a_shapes, 2, DataType::FLOAT32);
                uint64_t b_shapes[2] = {16, 16};
                Tensor ext_b = make_tensor_external(arg_b_ptr, b_shapes, 2, DataType::FLOAT32);
                uint64_t d_shapes[2] = {16, 16};
                Tensor ext_d = make_tensor_external(arg_d_ptr, d_shapes, 2, DataType::FLOAT32);

                uint64_t c_shapes[2] = {16, 16};
                Tensor c = make_tensor(c_shapes, 2, DataType::FLOAT32);

                // Task 0: kernel_add
                PTOParam params_t0[] = {
                    make_input_param(ext_a),
                    make_input_param(ext_b),
                    make_output_param(c),
                };
                pto2_rt_submit_task(rt, 0, PTO2_WORKER_VECTOR, params_t0, 3);

                // Task 1: kernel_add
                PTOParam params_t1[] = {
                    make_input_param(c),
                    make_input_param(ext_b),
                    make_output_param(ext_d),
                };
                pto2_rt_submit_task(rt, 0, PTO2_WORKER_VECTOR, params_t1, 3);
            }

            }  // extern "C"
        """
        assert_code_equal(code, expected)

    def test_tensor_read(self):
        """Test tensor.read uses arg_<name>_ptr."""
        backend.reset_for_testing()
        backend.set_backend_type(BackendType.CCE)

        @pl.program
        class TensorReadProgram:
            @pl.function(type=pl.FunctionType.InCore)
            def kernel_add(
                self,
                a: pl.Tensor[[16, 16], pl.FP32],
                b: pl.Tensor[[16, 16], pl.FP32],
                output: pl.Out[pl.Tensor[[16, 16], pl.FP32]],
            ) -> pl.Tensor[[16, 16], pl.FP32]:
                a_tile: pl.Tile[[16, 16], pl.FP32] = pl.load(a, [0, 0], [16, 16])
                b_tile: pl.Tile[[16, 16], pl.FP32] = pl.load(b, [0, 0], [16, 16])
                result: pl.Tile[[16, 16], pl.FP32] = pl.add(a_tile, b_tile)
                out: pl.Tensor[[16, 16], pl.FP32] = pl.store(result, [0, 0], [16, 16], output)
                return out

            @pl.function(type=pl.FunctionType.Orchestration)
            def orch_read(
                self,
                t: pl.Tensor[[4, 8], pl.FP32],
                a: pl.Tensor[[16, 16], pl.FP32],
                b: pl.Tensor[[16, 16], pl.FP32],
            ) -> pl.Tensor[[16, 16], pl.FP32]:
                val: pl.Scalar[pl.FP32] = pl.tensor.read(t, [1, 3])  # noqa: F841
                result: pl.Tensor[[16, 16], pl.FP32] = pl.create_tensor([16, 16], dtype=pl.FP32)
                result = self.kernel_add(a, b, result)
                return result

        generator = codegen.CCECodegen()
        files = generator.generate(TensorReadProgram)
        code = files["orchestration/orch_read.cpp"]

        # tensor.read uses arg_t_ptr, not host_t
        assert "idx_val" in code
        assert "static_cast<float*>(arg_t_ptr)" in code
        assert "host_t" not in code

    def test_config_file(self):
        """Test kernel_config.py is generated."""
        backend.reset_for_testing()
        backend.set_backend_type(BackendType.CCE)

        @pl.program
        class ConfigProgram:
            @pl.function(type=pl.FunctionType.InCore)
            def kernel_add(
                self,
                a: pl.Tensor[[16, 16], pl.FP32],
                b: pl.Tensor[[16, 16], pl.FP32],
                output: pl.Out[pl.Tensor[[16, 16], pl.FP32]],
            ) -> pl.Tensor[[16, 16], pl.FP32]:
                a_tile: pl.Tile[[16, 16], pl.FP32] = pl.load(a, [0, 0], [16, 16])
                b_tile: pl.Tile[[16, 16], pl.FP32] = pl.load(b, [0, 0], [16, 16])
                result: pl.Tile[[16, 16], pl.FP32] = pl.add(a_tile, b_tile)
                out: pl.Tensor[[16, 16], pl.FP32] = pl.store(result, [0, 0], [16, 16], output)
                return out

            @pl.function(type=pl.FunctionType.Orchestration)
            def orch_cfg(
                self,
                a: pl.Tensor[[16, 16], pl.FP32],
                b: pl.Tensor[[16, 16], pl.FP32],
            ) -> pl.Tensor[[16, 16], pl.FP32]:
                c: pl.Tensor[[16, 16], pl.FP32] = pl.create_tensor([16, 16], dtype=pl.FP32)
                c = self.kernel_add(a, b, c)
                return c

        generator = codegen.CCECodegen()
        files = generator.generate(ConfigProgram)

        assert "kernel_config.py" in files
        config = files["kernel_config.py"]
        assert "aicpu_orchestration_entry" in config
        assert "kernel_add" in config

    def test_independent_tasks(self):
        """Test codegen with independent tasks (no dependencies needed)."""
        backend.reset_for_testing()
        backend.set_backend_type(BackendType.CCE)

        @pl.program
        class IndependentProgram:
            @pl.function(type=pl.FunctionType.InCore)
            def kernel_add(
                self,
                a: pl.Tensor[[16, 16], pl.FP32],
                b: pl.Tensor[[16, 16], pl.FP32],
                output: pl.Out[pl.Tensor[[16, 16], pl.FP32]],
            ) -> pl.Tensor[[16, 16], pl.FP32]:
                a_tile: pl.Tile[[16, 16], pl.FP32] = pl.load(a, [0, 0], [16, 16])
                b_tile: pl.Tile[[16, 16], pl.FP32] = pl.load(b, [0, 0], [16, 16])
                result: pl.Tile[[16, 16], pl.FP32] = pl.add(a_tile, b_tile)
                out: pl.Tensor[[16, 16], pl.FP32] = pl.store(result, [0, 0], [16, 16], output)
                return out

            @pl.function(type=pl.FunctionType.Orchestration)
            def orch_indep(
                self,
                a: pl.Tensor[[16, 16], pl.FP32],
                b: pl.Tensor[[16, 16], pl.FP32],
            ) -> tuple[pl.Tensor[[16, 16], pl.FP32], pl.Tensor[[16, 16], pl.FP32]]:
                c: pl.Tensor[[16, 16], pl.FP32] = pl.create_tensor([16, 16], dtype=pl.FP32)
                c = self.kernel_add(a, b, c)
                d: pl.Tensor[[16, 16], pl.FP32] = pl.create_tensor([16, 16], dtype=pl.FP32)
                d = self.kernel_add(a, b, d)
                return c, d

        generator = codegen.CCECodegen()
        files = generator.generate(IndependentProgram)
        code = files["orchestration/orch_indep.cpp"]

        # Two return tensors: c and d are both external
        assert "ext_c" in code
        assert "ext_d" in code
        assert "make_tensor_external" in code

        # Two tasks submitted
        assert code.count("pto2_rt_submit_task") == 2

        # No PTO2_SCOPE needed: all tasks use only external tensors
        assert "PTO2_SCOPE" not in code

    def test_vector_example_dag(self):
        """Test codegen matching vector_example DAG structure.

        DAG:
          t0: c = kernel_add(a, b)           [outer scope]
          t1: d = kernel_add_scalar(c, 1.0)  [inner scope]
          t2: e = kernel_add_scalar(c, 2.0)  [inner scope]
          t3: g = kernel_mul(d, e)           [inner scope]
          t4: f = kernel_add(g, c)           [inner scope]
        Formula: f = (a + b + 1)(a + b + 2) + (a + b)
        """
        backend.reset_for_testing()
        backend.set_backend_type(BackendType.CCE)

        @pl.program
        class VectorExampleProgram:
            @pl.function(type=pl.FunctionType.InCore)
            def kernel_add(
                self,
                a: pl.Tensor[[16, 16], pl.FP32],
                b: pl.Tensor[[16, 16], pl.FP32],
                output: pl.Out[pl.Tensor[[16, 16], pl.FP32]],
            ) -> pl.Tensor[[16, 16], pl.FP32]:
                a_tile: pl.Tile[[16, 16], pl.FP32] = pl.load(a, [0, 0], [16, 16])
                b_tile: pl.Tile[[16, 16], pl.FP32] = pl.load(b, [0, 0], [16, 16])
                result: pl.Tile[[16, 16], pl.FP32] = pl.add(a_tile, b_tile)
                out: pl.Tensor[[16, 16], pl.FP32] = pl.store(result, [0, 0], [16, 16], output)
                return out

            @pl.function(type=pl.FunctionType.InCore)
            def kernel_add_scalar(
                self,
                a: pl.Tensor[[16, 16], pl.FP32],
                scalar: pl.Scalar[pl.FP32],
                output: pl.Out[pl.Tensor[[16, 16], pl.FP32]],
            ) -> pl.Tensor[[16, 16], pl.FP32]:
                x: pl.Tile[[16, 16], pl.FP32] = pl.load(a, [0, 0], [16, 16])
                result: pl.Tile[[16, 16], pl.FP32] = pl.add(x, scalar)
                out: pl.Tensor[[16, 16], pl.FP32] = pl.store(result, [0, 0], [16, 16], output)
                return out

            @pl.function(type=pl.FunctionType.InCore)
            def kernel_mul(
                self,
                a: pl.Tensor[[16, 16], pl.FP32],
                b: pl.Tensor[[16, 16], pl.FP32],
                output: pl.Out[pl.Tensor[[16, 16], pl.FP32]],
            ) -> pl.Tensor[[16, 16], pl.FP32]:
                a_tile: pl.Tile[[16, 16], pl.FP32] = pl.load(a, [0, 0], [16, 16])
                b_tile: pl.Tile[[16, 16], pl.FP32] = pl.load(b, [0, 0], [16, 16])
                result: pl.Tile[[16, 16], pl.FP32] = pl.mul(a_tile, b_tile)
                out: pl.Tensor[[16, 16], pl.FP32] = pl.store(result, [0, 0], [16, 16], output)
                return out

            @pl.function(type=pl.FunctionType.Orchestration)
            def orch_vector(
                self,
                a: pl.Tensor[[16, 16], pl.FP32],
                b: pl.Tensor[[16, 16], pl.FP32],
            ) -> pl.Tensor[[16, 16], pl.FP32]:
                c: pl.Tensor[[16, 16], pl.FP32] = pl.create_tensor([16, 16], dtype=pl.FP32)
                c = self.kernel_add(a, b, c)
                d: pl.Tensor[[16, 16], pl.FP32] = pl.create_tensor([16, 16], dtype=pl.FP32)
                d = self.kernel_add_scalar(c, 1.0, d)  # type: ignore[reportArgumentType]
                e: pl.Tensor[[16, 16], pl.FP32] = pl.create_tensor([16, 16], dtype=pl.FP32)
                e = self.kernel_add_scalar(c, 2.0, e)  # type: ignore[reportArgumentType]
                g: pl.Tensor[[16, 16], pl.FP32] = pl.create_tensor([16, 16], dtype=pl.FP32)
                g = self.kernel_mul(d, e, g)
                f: pl.Tensor[[16, 16], pl.FP32] = pl.create_tensor([16, 16], dtype=pl.FP32)
                f = self.kernel_add(g, c, f)
                return f

        generator = codegen.CCECodegen()
        files = generator.generate(VectorExampleProgram)
        code = files["orchestration/orch_vector.cpp"]

        expected = """\
            // Orchestration Function: orch_vector
            // Generated by PyPTO IR Compiler

            #include <stddef.h>
            #include <stdint.h>
            #include <stdio.h>

            #include "pto_orchestration_api.h"

            #define ARG_PTR_A 0
            #define ARG_PTR_B 1
            #define ARG_PTR_F 2

            // Helper to encode float as uint64_t for scalar params
            static uint64_t float_to_u64(float f) {
                union {
                    float f32;
                    uint64_t u64;
                } conv;
                conv.u64 = 0;  // Clear upper bits
                conv.f32 = f;
                return conv.u64;
            }

            extern "C" {

            __attribute__((visibility("default")))
            PTO2OrchestrationConfig aicpu_orchestration_config(uint64_t* args, int arg_count) {
                (void)args;
                (void)arg_count;
                return PTO2OrchestrationConfig{
                    .expected_arg_count = 3,
                };
            }

            __attribute__((visibility("default")))
            void aicpu_orchestration_entry(PTO2Runtime* rt, uint64_t* args, int arg_count) {
                (void)arg_count;

                // Extract device pointers
                void* arg_a_ptr = reinterpret_cast<void*>(args[ARG_PTR_A]);
                void* arg_b_ptr = reinterpret_cast<void*>(args[ARG_PTR_B]);
                void* arg_f_ptr = reinterpret_cast<void*>(args[ARG_PTR_F]);

                // External tensors
                uint64_t a_shapes[2] = {16, 16};
                Tensor ext_a = make_tensor_external(arg_a_ptr, a_shapes, 2, DataType::FLOAT32);
                uint64_t b_shapes[2] = {16, 16};
                Tensor ext_b = make_tensor_external(arg_b_ptr, b_shapes, 2, DataType::FLOAT32);
                uint64_t f_shapes[2] = {16, 16};
                Tensor ext_f = make_tensor_external(arg_f_ptr, f_shapes, 2, DataType::FLOAT32);

                uint64_t c_shapes[2] = {16, 16};
                Tensor c = make_tensor(c_shapes, 2, DataType::FLOAT32);

                // Task 0: kernel_add
                PTOParam params_t0[] = {
                    make_input_param(ext_a),
                    make_input_param(ext_b),
                    make_output_param(c),
                };
                pto2_rt_submit_task(rt, 0, PTO2_WORKER_VECTOR, params_t0, 3);
                uint64_t d_shapes[2] = {16, 16};
                Tensor d = make_tensor(d_shapes, 2, DataType::FLOAT32);

                // Task 1: kernel_add_scalar
                PTOParam params_t1[] = {
                    make_input_param(c),
                    make_scalar_param(float_to_u64(1.000000f)),
                    make_output_param(d),
                };
                pto2_rt_submit_task(rt, 1, PTO2_WORKER_VECTOR, params_t1, 3);
                uint64_t e_shapes[2] = {16, 16};
                Tensor e = make_tensor(e_shapes, 2, DataType::FLOAT32);

                // Task 2: kernel_add_scalar
                PTOParam params_t2[] = {
                    make_input_param(c),
                    make_scalar_param(float_to_u64(2.000000f)),
                    make_output_param(e),
                };
                pto2_rt_submit_task(rt, 1, PTO2_WORKER_VECTOR, params_t2, 3);
                uint64_t g_shapes[2] = {16, 16};
                Tensor g = make_tensor(g_shapes, 2, DataType::FLOAT32);

                // Task 3: kernel_mul
                PTOParam params_t3[] = {
                    make_input_param(d),
                    make_input_param(e),
                    make_output_param(g),
                };
                pto2_rt_submit_task(rt, 2, PTO2_WORKER_VECTOR, params_t3, 3);

                // Task 4: kernel_add
                PTOParam params_t4[] = {
                    make_input_param(g),
                    make_input_param(c),
                    make_output_param(ext_f),
                };
                pto2_rt_submit_task(rt, 0, PTO2_WORKER_VECTOR, params_t4, 3);
            }

            }  // extern "C"
        """
        assert_code_equal(code, expected)

    def test_tuple_intermediate(self):
        """Test tuple return as intermediate tensors: kernel_pair -> kernel_add."""
        backend.reset_for_testing()
        backend.set_backend_type(BackendType.CCE)

        @pl.program
        class TupleIntermediateProgram:
            @pl.function(type=pl.FunctionType.InCore)
            def kernel_pair(
                self,
                a: pl.Tensor[[16, 16], pl.FP32],
                b: pl.Tensor[[16, 16], pl.FP32],
                out_s: pl.Out[pl.Tensor[[16, 16], pl.FP32]],
                out_d: pl.Out[pl.Tensor[[16, 16], pl.FP32]],
            ) -> tuple[pl.Tensor[[16, 16], pl.FP32], pl.Tensor[[16, 16], pl.FP32]]:
                a_tile: pl.Tile[[16, 16], pl.FP32] = pl.load(a, [0, 0], [16, 16])
                b_tile: pl.Tile[[16, 16], pl.FP32] = pl.load(b, [0, 0], [16, 16])
                s: pl.Tile[[16, 16], pl.FP32] = pl.add(a_tile, b_tile)
                d: pl.Tile[[16, 16], pl.FP32] = pl.sub(a_tile, b_tile)
                rs: pl.Tensor[[16, 16], pl.FP32] = pl.store(s, [0, 0], [16, 16], out_s)
                rd: pl.Tensor[[16, 16], pl.FP32] = pl.store(d, [0, 0], [16, 16], out_d)
                return rs, rd

            @pl.function(type=pl.FunctionType.InCore)
            def kernel_add(
                self,
                a: pl.Tensor[[16, 16], pl.FP32],
                b: pl.Tensor[[16, 16], pl.FP32],
                output: pl.Out[pl.Tensor[[16, 16], pl.FP32]],
            ) -> pl.Tensor[[16, 16], pl.FP32]:
                a_tile: pl.Tile[[16, 16], pl.FP32] = pl.load(a, [0, 0], [16, 16])
                b_tile: pl.Tile[[16, 16], pl.FP32] = pl.load(b, [0, 0], [16, 16])
                result: pl.Tile[[16, 16], pl.FP32] = pl.add(a_tile, b_tile)
                out: pl.Tensor[[16, 16], pl.FP32] = pl.store(result, [0, 0], [16, 16], output)
                return out

            @pl.function(type=pl.FunctionType.Orchestration)
            def orch_tuple_mid(
                self,
                a: pl.Tensor[[16, 16], pl.FP32],
                b: pl.Tensor[[16, 16], pl.FP32],
            ) -> pl.Tensor[[16, 16], pl.FP32]:
                x: pl.Tensor[[16, 16], pl.FP32] = pl.create_tensor([16, 16], dtype=pl.FP32)
                y: pl.Tensor[[16, 16], pl.FP32] = pl.create_tensor([16, 16], dtype=pl.FP32)
                x, y = self.kernel_pair(a, b, x, y)
                result: pl.Tensor[[16, 16], pl.FP32] = pl.create_tensor([16, 16], dtype=pl.FP32)
                result = self.kernel_add(x, y, result)
                return result

        generator = codegen.CCECodegen()
        files = generator.generate(TupleIntermediateProgram)
        code = files["orchestration/orch_tuple_mid.cpp"]

        # Tuple elements x, y are intermediate: make_tensor (not external)
        assert "Tensor x = make_tensor(" in code
        assert "Tensor y = make_tensor(" in code
        assert "DataType::FLOAT32" in code

        # Return tensor result is external
        assert "make_tensor_external(arg_result_ptr" in code

        # Two tasks: kernel_pair + kernel_add
        assert code.count("pto2_rt_submit_task") == 2

        # No PTO2_SCOPE: no control flow
        assert "PTO2_SCOPE" not in code

    def test_tuple_output(self):
        """Test tuple return as final output: all elements are external tensors."""
        backend.reset_for_testing()
        backend.set_backend_type(BackendType.CCE)

        @pl.program
        class TupleOutputProgram:
            @pl.function(type=pl.FunctionType.InCore)
            def kernel_pair(
                self,
                a: pl.Tensor[[16, 16], pl.FP32],
                b: pl.Tensor[[16, 16], pl.FP32],
                out_s: pl.Out[pl.Tensor[[16, 16], pl.FP32]],
                out_d: pl.Out[pl.Tensor[[16, 16], pl.FP32]],
            ) -> tuple[pl.Tensor[[16, 16], pl.FP32], pl.Tensor[[16, 16], pl.FP32]]:
                a_tile: pl.Tile[[16, 16], pl.FP32] = pl.load(a, [0, 0], [16, 16])
                b_tile: pl.Tile[[16, 16], pl.FP32] = pl.load(b, [0, 0], [16, 16])
                s: pl.Tile[[16, 16], pl.FP32] = pl.add(a_tile, b_tile)
                d: pl.Tile[[16, 16], pl.FP32] = pl.sub(a_tile, b_tile)
                rs: pl.Tensor[[16, 16], pl.FP32] = pl.store(s, [0, 0], [16, 16], out_s)
                rd: pl.Tensor[[16, 16], pl.FP32] = pl.store(d, [0, 0], [16, 16], out_d)
                return rs, rd

            @pl.function(type=pl.FunctionType.Orchestration)
            def orch_tuple_out(
                self,
                a: pl.Tensor[[16, 16], pl.FP32],
                b: pl.Tensor[[16, 16], pl.FP32],
            ) -> tuple[pl.Tensor[[16, 16], pl.FP32], pl.Tensor[[16, 16], pl.FP32]]:
                x: pl.Tensor[[16, 16], pl.FP32] = pl.create_tensor([16, 16], dtype=pl.FP32)
                y: pl.Tensor[[16, 16], pl.FP32] = pl.create_tensor([16, 16], dtype=pl.FP32)
                x, y = self.kernel_pair(a, b, x, y)
                return x, y

        generator = codegen.CCECodegen()
        files = generator.generate(TupleOutputProgram)
        code = files["orchestration/orch_tuple_out.cpp"]

        # Both x and y are return tensors: make_tensor_external
        assert "ext_x" in code
        assert "ext_y" in code
        assert "make_tensor_external(arg_x_ptr" in code
        assert "make_tensor_external(arg_y_ptr" in code

        # Only one task: kernel_pair
        assert code.count("pto2_rt_submit_task") == 1

        # No PTO2_SCOPE needed: single task, all external
        assert "PTO2_SCOPE" not in code

    def test_four_element_tuple(self):
        """Test 4-element tuple unpacking with mixed shapes as intermediate."""
        backend.reset_for_testing()
        backend.set_backend_type(BackendType.CCE)

        @pl.program
        class FourTupleProgram:
            @pl.function(type=pl.FunctionType.InCore)
            def online_update(
                self,
                mij: pl.Tensor[[16, 1], pl.FP32],
                lij: pl.Tensor[[16, 1], pl.FP32],
                oi_new: pl.Tensor[[16, 16], pl.FP32],
                mi: pl.InOut[pl.Tensor[[16, 1], pl.FP32]],
                li: pl.InOut[pl.Tensor[[16, 1], pl.FP32]],
                oi: pl.InOut[pl.Tensor[[16, 16], pl.FP32]],
                dst: pl.Out[pl.Tensor[[16, 16], pl.FP32]],
            ) -> tuple[
                pl.Tensor[[16, 1], pl.FP32],
                pl.Tensor[[16, 1], pl.FP32],
                pl.Tensor[[16, 16], pl.FP32],
                pl.Tensor[[16, 16], pl.FP32],
            ]:
                mi_tile: pl.Tile[[16, 1], pl.FP32] = pl.load(mi, [0, 0], [16, 1])
                li_tile: pl.Tile[[16, 1], pl.FP32] = pl.load(li, [0, 0], [16, 1])
                oi_tile: pl.Tile[[16, 16], pl.FP32] = pl.load(oi, [0, 0], [16, 16])
                dst_tile: pl.Tile[[16, 16], pl.FP32] = pl.load(dst, [0, 0], [16, 16])
                mi_out: pl.Tensor[[16, 1], pl.FP32] = pl.store(mi_tile, [0, 0], [16, 1], mi)
                li_out: pl.Tensor[[16, 1], pl.FP32] = pl.store(li_tile, [0, 0], [16, 1], li)
                oi_out: pl.Tensor[[16, 16], pl.FP32] = pl.store(oi_tile, [0, 0], [16, 16], oi)
                dst_out: pl.Tensor[[16, 16], pl.FP32] = pl.store(dst_tile, [0, 0], [16, 16], dst)
                return mi_out, li_out, oi_out, dst_out

            @pl.function(type=pl.FunctionType.InCore)
            def kernel_add(
                self,
                a: pl.Tensor[[16, 16], pl.FP32],
                b: pl.Tensor[[16, 16], pl.FP32],
                output: pl.Out[pl.Tensor[[16, 16], pl.FP32]],
            ) -> pl.Tensor[[16, 16], pl.FP32]:
                a_tile: pl.Tile[[16, 16], pl.FP32] = pl.load(a, [0, 0], [16, 16])
                b_tile: pl.Tile[[16, 16], pl.FP32] = pl.load(b, [0, 0], [16, 16])
                result: pl.Tile[[16, 16], pl.FP32] = pl.add(a_tile, b_tile)
                out: pl.Tensor[[16, 16], pl.FP32] = pl.store(result, [0, 0], [16, 16], output)
                return out

            @pl.function(type=pl.FunctionType.Orchestration)
            def orch_four_tuple(
                self,
                mij: pl.Tensor[[16, 1], pl.FP32],
                lij: pl.Tensor[[16, 1], pl.FP32],
                oi_new: pl.Tensor[[16, 16], pl.FP32],
                mi_in: pl.Tensor[[16, 1], pl.FP32],
                li_in: pl.Tensor[[16, 1], pl.FP32],
                oi_in: pl.Tensor[[16, 16], pl.FP32],
                dst_in: pl.Tensor[[16, 16], pl.FP32],
            ) -> pl.Tensor[[16, 16], pl.FP32]:
                mi_in, li_in, oi_in, dst_in = self.online_update(
                    mij, lij, oi_new, mi_in, li_in, oi_in, dst_in
                )
                final: pl.Tensor[[16, 16], pl.FP32] = pl.create_tensor([16, 16], dtype=pl.FP32)
                final = self.kernel_add(oi_in, dst_in, final)
                return final

        generator = codegen.CCECodegen()
        files = generator.generate(FourTupleProgram)
        code = files["orchestration/orch_four_tuple.cpp"]

        # All orch params are external tensors
        assert "make_tensor_external(arg_mi_in_ptr" in code
        assert "make_tensor_external(arg_oi_in_ptr" in code
        assert "make_tensor_external(arg_dst_in_ptr" in code

        # Final return tensor is external
        assert "make_tensor_external(arg_final_ptr" in code

        # Two tasks: online_update + kernel_add
        assert code.count("pto2_rt_submit_task") == 2

        # online_update: 3 In + 3 InOut + 1 Out = 7 params
        assert "make_input_param(ext_mij)" in code
        assert "make_inout_param(ext_mi_in)" in code
        assert "make_output_param(ext_dst_in)" in code

        # kernel_add: 2 In + 1 Out = 3 params
        assert "make_input_param(ext_oi_in)" in code
        assert "make_output_param(ext_final)" in code

        # No PTO2_SCOPE: no control flow
        assert "PTO2_SCOPE" not in code

    def test_tensor_create(self):
        """Test tensor.create generates make_tensor with correct size."""
        backend.reset_for_testing()
        backend.set_backend_type(BackendType.CCE)

        @pl.program
        class TensorCreateProgram:
            @pl.function(type=pl.FunctionType.InCore)
            def kernel_fill(
                self,
                a: pl.Tensor[[32, 32], pl.FP16],
                output: pl.Out[pl.Tensor[[32, 32], pl.FP16]],
            ) -> pl.Tensor[[32, 32], pl.FP16]:
                t: pl.Tile[[32, 32], pl.FP16] = pl.load(a, [0, 0], [32, 32])
                out: pl.Tensor[[32, 32], pl.FP16] = pl.store(t, [0, 0], [32, 32], output)
                return out

            @pl.function(type=pl.FunctionType.Orchestration)
            def orch_create(
                self,
                a: pl.Tensor[[32, 32], pl.FP16],
            ) -> pl.Tensor[[32, 32], pl.FP16]:
                buf: pl.Tensor[[32, 32], pl.FP16] = pl.create_tensor([32, 32], dtype=pl.FP16)
                result: pl.Tensor[[32, 32], pl.FP16] = pl.create_tensor([32, 32], dtype=pl.FP16)
                result = self.kernel_fill(buf, result)
                return result

        generator = codegen.CCECodegen()
        files = generator.generate(TensorCreateProgram)
        code = files["orchestration/orch_create.cpp"]

        # tensor.create generates make_tensor with shape/dtype
        # FP16 = DataType::FLOAT16
        assert "buf_shapes[2] = {32, 32}" in code
        assert "Tensor buf = make_tensor(buf_shapes, 2, DataType::FLOAT16)" in code

    def test_inplace_tensor(self):
        """Test inplace tensors use make_inout_param when a tensor is both input and output.

        Pattern from OnlineUpdateMultiOut: mi, li, oi are passed as input args
        and also appear as output (tuple return elements) of the same kernel call.
        The codegen should emit make_inout_param for these inplace tensors.
        """
        backend.reset_for_testing()
        backend.set_backend_type(BackendType.CCE)

        @pl.program
        class InplaceProgram:
            @pl.function(type=pl.FunctionType.InCore)
            def online_update(
                self,
                mij: pl.Tensor[[16, 1], pl.FP32],
                lij: pl.Tensor[[16, 1], pl.FP32],
                oi_new: pl.Tensor[[16, 16], pl.FP32],
                mi: pl.InOut[pl.Tensor[[16, 1], pl.FP32]],
                li: pl.InOut[pl.Tensor[[16, 1], pl.FP32]],
                oi: pl.InOut[pl.Tensor[[16, 16], pl.FP32]],
                dst: pl.Out[pl.Tensor[[16, 16], pl.FP32]],
            ) -> tuple[
                pl.Tensor[[16, 1], pl.FP32],
                pl.Tensor[[16, 1], pl.FP32],
                pl.Tensor[[16, 16], pl.FP32],
                pl.Tensor[[16, 16], pl.FP32],
            ]:
                mi_tile: pl.Tile[[16, 1], pl.FP32] = pl.load(mi, [0, 0], [16, 1])
                li_tile: pl.Tile[[16, 1], pl.FP32] = pl.load(li, [0, 0], [16, 1])
                oi_tile: pl.Tile[[16, 16], pl.FP32] = pl.load(oi, [0, 0], [16, 16])
                dst_tile: pl.Tile[[16, 16], pl.FP32] = pl.load(dst, [0, 0], [16, 16])
                mi_out: pl.Tensor[[16, 1], pl.FP32] = pl.store(mi_tile, [0, 0], [16, 1], mi)
                li_out: pl.Tensor[[16, 1], pl.FP32] = pl.store(li_tile, [0, 0], [16, 1], li)
                oi_out: pl.Tensor[[16, 16], pl.FP32] = pl.store(oi_tile, [0, 0], [16, 16], oi)
                dst_out: pl.Tensor[[16, 16], pl.FP32] = pl.store(dst_tile, [0, 0], [16, 16], dst)
                return mi_out, li_out, oi_out, dst_out

            @pl.function(type=pl.FunctionType.Orchestration)
            def orch_inplace(
                self,
                mij: pl.Tensor[[16, 1], pl.FP32],
                lij: pl.Tensor[[16, 1], pl.FP32],
                oi_new: pl.Tensor[[16, 16], pl.FP32],
                mi: pl.Tensor[[16, 1], pl.FP32],
                li: pl.Tensor[[16, 1], pl.FP32],
                oi: pl.Tensor[[16, 16], pl.FP32],
            ) -> tuple[
                pl.Tensor[[16, 1], pl.FP32],
                pl.Tensor[[16, 1], pl.FP32],
                pl.Tensor[[16, 16], pl.FP32],
                pl.Tensor[[16, 16], pl.FP32],
            ]:
                dst: pl.Tensor[[16, 16], pl.FP32] = pl.create_tensor([16, 16], dtype=pl.FP32)
                mi, li, oi, dst = self.online_update(mij, lij, oi_new, mi, li, oi, dst)
                return mi, li, oi, dst

        generator = codegen.CCECodegen()
        files = generator.generate(InplaceProgram)
        code = files["orchestration/orch_inplace.cpp"]

        expected = """\
            // Orchestration Function: orch_inplace
            // Generated by PyPTO IR Compiler

            #include <stddef.h>
            #include <stdint.h>
            #include <stdio.h>

            #include "pto_orchestration_api.h"

            #define ARG_PTR_MIJ 0
            #define ARG_PTR_LIJ 1
            #define ARG_PTR_OI_NEW 2
            #define ARG_PTR_MI 3
            #define ARG_PTR_LI 4
            #define ARG_PTR_OI 5
            #define ARG_PTR_DST 6

            // Helper to encode float as uint64_t for scalar params
            static uint64_t float_to_u64(float f) {
                union {
                    float f32;
                    uint64_t u64;
                } conv;
                conv.u64 = 0;  // Clear upper bits
                conv.f32 = f;
                return conv.u64;
            }

            extern "C" {

            __attribute__((visibility("default")))
            PTO2OrchestrationConfig aicpu_orchestration_config(uint64_t* args, int arg_count) {
                (void)args;
                (void)arg_count;
                return PTO2OrchestrationConfig{
                    .expected_arg_count = 7,
                };
            }

            __attribute__((visibility("default")))
            void aicpu_orchestration_entry(PTO2Runtime* rt, uint64_t* args, int arg_count) {
                (void)arg_count;

                // Extract device pointers
                void* arg_mij_ptr = reinterpret_cast<void*>(args[ARG_PTR_MIJ]);
                void* arg_lij_ptr = reinterpret_cast<void*>(args[ARG_PTR_LIJ]);
                void* arg_oi_new_ptr = reinterpret_cast<void*>(args[ARG_PTR_OI_NEW]);
                void* arg_mi_ptr = reinterpret_cast<void*>(args[ARG_PTR_MI]);
                void* arg_li_ptr = reinterpret_cast<void*>(args[ARG_PTR_LI]);
                void* arg_oi_ptr = reinterpret_cast<void*>(args[ARG_PTR_OI]);
                void* arg_dst_ptr = reinterpret_cast<void*>(args[ARG_PTR_DST]);

                // External tensors
                uint64_t mij_shapes[2] = {16, 1};
                Tensor ext_mij = make_tensor_external(arg_mij_ptr, mij_shapes, 2, DataType::FLOAT32);
                uint64_t lij_shapes[2] = {16, 1};
                Tensor ext_lij = make_tensor_external(arg_lij_ptr, lij_shapes, 2, DataType::FLOAT32);
                uint64_t oi_new_shapes[2] = {16, 16};
                Tensor ext_oi_new = make_tensor_external(arg_oi_new_ptr, oi_new_shapes, 2, DataType::FLOAT32);
                uint64_t mi_shapes[2] = {16, 1};
                Tensor ext_mi = make_tensor_external(arg_mi_ptr, mi_shapes, 2, DataType::FLOAT32);
                uint64_t li_shapes[2] = {16, 1};
                Tensor ext_li = make_tensor_external(arg_li_ptr, li_shapes, 2, DataType::FLOAT32);
                uint64_t oi_shapes[2] = {16, 16};
                Tensor ext_oi = make_tensor_external(arg_oi_ptr, oi_shapes, 2, DataType::FLOAT32);
                uint64_t dst_shapes[2] = {16, 16};
                Tensor ext_dst = make_tensor_external(arg_dst_ptr, dst_shapes, 2, DataType::FLOAT32);


                // Task 0: online_update
                PTOParam params_t0[] = {
                    make_input_param(ext_mij),
                    make_input_param(ext_lij),
                    make_input_param(ext_oi_new),
                    make_inout_param(ext_mi),
                    make_inout_param(ext_li),
                    make_inout_param(ext_oi),
                    make_output_param(ext_dst),
                };
                pto2_rt_submit_task(rt, 0, PTO2_WORKER_VECTOR, params_t0, 7);
            }

            }  // extern "C"
        """
        assert_code_equal(code, expected)

    def test_tensor_dim(self):
        """Test tensor.dim generates int64_t assignment with shape value."""
        backend.reset_for_testing()
        backend.set_backend_type(BackendType.CCE)

        @pl.program
        class TensorDimProgram:
            @pl.function(type=pl.FunctionType.InCore)
            def kernel_add(
                self,
                a: pl.Tensor[[16, 16], pl.FP32],
                b: pl.Tensor[[16, 16], pl.FP32],
                output: pl.Out[pl.Tensor[[16, 16], pl.FP32]],
            ) -> pl.Tensor[[16, 16], pl.FP32]:
                a_tile: pl.Tile[[16, 16], pl.FP32] = pl.load(a, [0, 0], [16, 16])
                b_tile: pl.Tile[[16, 16], pl.FP32] = pl.load(b, [0, 0], [16, 16])
                result: pl.Tile[[16, 16], pl.FP32] = pl.add(a_tile, b_tile)
                out: pl.Tensor[[16, 16], pl.FP32] = pl.store(result, [0, 0], [16, 16], output)
                return out

            @pl.function(type=pl.FunctionType.Orchestration)
            def orch_dim(
                self,
                a: pl.Tensor[[64, 128], pl.FP32],
                b: pl.Tensor[[64, 128], pl.FP32],
            ) -> pl.Tensor[[64, 128], pl.FP32]:
                d0: pl.Scalar[pl.INT64] = pl.tensor.dim(a, 0)  # noqa: F841
                result: pl.Tensor[[64, 128], pl.FP32] = pl.create_tensor([64, 128], dtype=pl.FP32)
                result = self.kernel_add(a, b, result)
                return result

        generator = codegen.CCECodegen()
        files = generator.generate(TensorDimProgram)
        code = files["orchestration/orch_dim.cpp"]

        # tensor.dim generates int64_t assignment
        assert "int64_t d0 = 64" in code

    def test_for_loop_with_view(self):
        """Test for loop + tensor.view: simplified paged attention pattern.

        Exercises: for loop with dynamic bound, tensor.view with dynamic offsets,
        kernel calls inside loop body.
        """
        backend.reset_for_testing()
        backend.set_backend_type(BackendType.CCE)

        @pl.program
        class ForViewProgram:
            @pl.function(type=pl.FunctionType.InCore)
            def kernel_add(
                self,
                a: pl.Tensor[[16, 16], pl.FP32],
                b: pl.Tensor[[16, 16], pl.FP32],
                output: pl.Out[pl.Tensor[[16, 16], pl.FP32]],
            ) -> pl.Tensor[[16, 16], pl.FP32]:
                a_tile: pl.Tile[[16, 16], pl.FP32] = pl.load(a, [0, 0], [16, 16])
                b_tile: pl.Tile[[16, 16], pl.FP32] = pl.load(b, [0, 0], [16, 16])
                result: pl.Tile[[16, 16], pl.FP32] = pl.add(a_tile, b_tile)
                out: pl.Tensor[[16, 16], pl.FP32] = pl.store(result, [0, 0], [16, 16], output)
                return out

            @pl.function(type=pl.FunctionType.Orchestration)
            def orch_for_view(
                self,
                data: pl.Tensor[[64, 16], pl.FP32],
                bias: pl.Tensor[[16, 16], pl.FP32],
                config: pl.Tensor[[4], pl.INT64],
            ) -> pl.Tensor[[64, 16], pl.FP32]:
                n_blocks: pl.Scalar[pl.INT64] = pl.tensor.read(config, [0])
                out: pl.Tensor[[64, 16], pl.FP32] = data
                for i in pl.range(n_blocks):
                    chunk: pl.Tensor[[16, 16], pl.FP32] = pl.view(data, [16, 16], [i * 16, 0])
                    result: pl.Tensor[[16, 16], pl.FP32] = pl.create_tensor([16, 16], dtype=pl.FP32)
                    result = self.kernel_add(chunk, bias, result)  # noqa: F841
                return out

        generator = codegen.CCECodegen()
        files = generator.generate(ForViewProgram)
        code = files["orchestration/orch_for_view.cpp"]

        # For loop with dynamic bound from tensor.read
        assert "for (int64_t i = 0; i < n_blocks; i += 1)" in code

        # PTO2_SCOPE wraps the for loop body
        assert "PTO2_SCOPE(rt)" in code

        # tensor.view generates view call with dynamic offset
        assert ".view({16, 16}, {(i * 16), 0})" in code

        # tensor.read generates host pointer access
        assert "static_cast<int64_t*>(arg_config_ptr)" in code

        # kernel_add task submitted inside loop
        assert "pto2_rt_submit_task" in code

    def test_if_statement(self):
        """Test if/else codegen with conditional scalar values."""
        backend.reset_for_testing()
        backend.set_backend_type(BackendType.CCE)

        @pl.program
        class IfProgram:
            @pl.function(type=pl.FunctionType.InCore)
            def kernel_process(
                self,
                a: pl.Tensor[[16, 16], pl.FP32],
                flag: pl.Scalar[pl.INT64],
                output: pl.Out[pl.Tensor[[16, 16], pl.FP32]],
            ) -> pl.Tensor[[16, 16], pl.FP32]:
                t: pl.Tile[[16, 16], pl.FP32] = pl.load(a, [0, 0], [16, 16])
                out: pl.Tensor[[16, 16], pl.FP32] = pl.store(t, [0, 0], [16, 16], output)
                return out

            @pl.function(type=pl.FunctionType.Orchestration)
            def orch_if(
                self,
                a: pl.Tensor[[16, 16], pl.FP32],
            ) -> pl.Tensor[[16, 16], pl.FP32]:
                for i in pl.range(4):
                    if i == 0:
                        is_first: pl.Scalar[pl.INT64] = pl.yield_(1)
                    else:
                        is_first: pl.Scalar[pl.INT64] = pl.yield_(0)
                    result: pl.Tensor[[16, 16], pl.FP32] = pl.create_tensor([16, 16], dtype=pl.FP32)
                    result = self.kernel_process(a, is_first, result)
                return result

        generator = codegen.CCECodegen()
        files = generator.generate(IfProgram)
        code = files["orchestration/orch_if.cpp"]

        # If statement with comparison
        assert "if ((i == 0))" in code

        # PTO2_SCOPE wraps for loop body and if/else bodies
        assert "PTO2_SCOPE(rt)" in code

        # Scalar assignment in both branches
        assert "is_first = 1" in code
        assert "is_first = 0" in code

    def test_multiple_tuple_calls(self):
        """Test that multiple tuple-returning calls produce correct per-call params.

        When two different kernel calls both return tuples, each call's PTOParam
        array should only contain outputs from that specific call, not outputs
        from other calls. Regression test for SSA base name collision in
        tuple_var_to_elements_ (all _tuple_tmp_N collapsed to _tuple_tmp).
        """
        backend.reset_for_testing()
        backend.set_backend_type(BackendType.CCE)

        @pl.program
        class MultipleTupleProgram:
            @pl.function(type=pl.FunctionType.InCore)
            def kernel_a(
                self,
                x: pl.InOut[pl.Tensor[[16, 16], pl.FP32]],
                y: pl.InOut[pl.Tensor[[16, 16], pl.FP32]],
            ) -> tuple[
                pl.Tensor[[16, 16], pl.FP32],
                pl.Tensor[[16, 16], pl.FP32],
            ]:
                xt: pl.Tile[[16, 16], pl.FP32] = pl.load(x, [0, 0], [16, 16])
                yt: pl.Tile[[16, 16], pl.FP32] = pl.load(y, [0, 0], [16, 16])
                x_out: pl.Tensor[[16, 16], pl.FP32] = pl.store(xt, [0, 0], [16, 16], x)
                y_out: pl.Tensor[[16, 16], pl.FP32] = pl.store(yt, [0, 0], [16, 16], y)
                return x_out, y_out

            @pl.function(type=pl.FunctionType.InCore)
            def kernel_b(
                self,
                a: pl.InOut[pl.Tensor[[16, 16], pl.FP32]],
                b: pl.InOut[pl.Tensor[[16, 16], pl.FP32]],
            ) -> tuple[
                pl.Tensor[[16, 16], pl.FP32],
                pl.Tensor[[16, 16], pl.FP32],
            ]:
                at: pl.Tile[[16, 16], pl.FP32] = pl.load(a, [0, 0], [16, 16])
                bt: pl.Tile[[16, 16], pl.FP32] = pl.load(b, [0, 0], [16, 16])
                a_out: pl.Tensor[[16, 16], pl.FP32] = pl.store(at, [0, 0], [16, 16], a)
                b_out: pl.Tensor[[16, 16], pl.FP32] = pl.store(bt, [0, 0], [16, 16], b)
                return a_out, b_out

            @pl.function(type=pl.FunctionType.Orchestration)
            def orch_multi_tuple(
                self,
                x: pl.Tensor[[16, 16], pl.FP32],
                y: pl.Tensor[[16, 16], pl.FP32],
                a: pl.Tensor[[16, 16], pl.FP32],
                b: pl.Tensor[[16, 16], pl.FP32],
            ) -> pl.Tensor[[16, 16], pl.FP32]:
                # First tuple-returning call
                x, y = self.kernel_a(x, y)
                # Second tuple-returning call
                a, b = self.kernel_b(a, b)
                return x

        generator = codegen.CCECodegen()
        files = generator.generate(MultipleTupleProgram)
        code = files["orchestration/orch_multi_tuple.cpp"]

        # kernel_a should only have x and y params (2 inout), not a or b
        assert code.count("params_t0") >= 2
        # kernel_b should only have a and b params (2 inout), not x or y
        assert code.count("params_t1") >= 2

        # Count make_inout_param per task block: each should have exactly 2
        lines = code.split("\n")
        task0_params = []
        task1_params = []
        in_task0 = False
        in_task1 = False
        for line in lines:
            if "params_t0[]" in line:
                in_task0 = True
            elif "params_t1[]" in line:
                in_task1 = True
            elif "};" in line:
                in_task0 = False
                in_task1 = False
            if in_task0 and ("make_" in line):
                task0_params.append(line.strip())
            if in_task1 and ("make_" in line):
                task1_params.append(line.strip())

        # kernel_a: x, y as inout → 2 params
        assert len(task0_params) == 2, (
            f"kernel_a should have 2 params (x, y inout), got {len(task0_params)}: {task0_params}"
        )
        # kernel_b: a, b as inout → 2 params
        assert len(task1_params) == 2, (
            f"kernel_b should have 2 params (a, b inout), got {len(task1_params)}: {task1_params}"
        )

    def test_tuple_in_for_loop(self):
        """Test tuple-returning call inside for-loop produces no self-assignments.

        When a tuple-returning kernel is called both before and inside a for-loop,
        SSA conversion creates iter_args for the tuple intermediate (_tuple_tmp) and
        its unpacked elements. After SSA base name collapsing, these would produce
        self-assignments like `auto _tuple_tmp = _tuple_tmp;` (C++ UB) and
        `oi = oi;` (NOP). The codegen should skip these.
        """
        backend.reset_for_testing()
        backend.set_backend_type(BackendType.CCE)

        @pl.program
        class TupleForLoopProgram:
            @pl.function(type=pl.FunctionType.InCore)
            def kernel_init(
                self,
                a: pl.InOut[pl.Tensor[[16, 16], pl.FP32]],
                b: pl.InOut[pl.Tensor[[16, 16], pl.FP32]],
            ) -> tuple[
                pl.Tensor[[16, 16], pl.FP32],
                pl.Tensor[[16, 16], pl.FP32],
            ]:
                at: pl.Tile[[16, 16], pl.FP32] = pl.load(a, [0, 0], [16, 16])
                bt: pl.Tile[[16, 16], pl.FP32] = pl.load(b, [0, 0], [16, 16])
                a_out: pl.Tensor[[16, 16], pl.FP32] = pl.store(at, [0, 0], [16, 16], a)
                b_out: pl.Tensor[[16, 16], pl.FP32] = pl.store(bt, [0, 0], [16, 16], b)
                return a_out, b_out

            @pl.function(type=pl.FunctionType.InCore)
            def kernel_update(
                self,
                x: pl.Tensor[[16, 16], pl.FP32],
                a: pl.InOut[pl.Tensor[[16, 16], pl.FP32]],
                b: pl.InOut[pl.Tensor[[16, 16], pl.FP32]],
            ) -> tuple[
                pl.Tensor[[16, 16], pl.FP32],
                pl.Tensor[[16, 16], pl.FP32],
            ]:
                xt: pl.Tile[[16, 16], pl.FP32] = pl.load(x, [0, 0], [16, 16])
                at: pl.Tile[[16, 16], pl.FP32] = pl.load(a, [0, 0], [16, 16])
                a_out: pl.Tensor[[16, 16], pl.FP32] = pl.store(xt, [0, 0], [16, 16], a)
                b_out: pl.Tensor[[16, 16], pl.FP32] = pl.store(at, [0, 0], [16, 16], b)
                return a_out, b_out

            @pl.function(type=pl.FunctionType.Orchestration)
            def orch_tuple_loop(
                self,
                x: pl.Tensor[[16, 16], pl.FP32],
            ) -> pl.Tensor[[16, 16], pl.FP32]:
                a_acc: pl.Tensor[[16, 16], pl.FP32] = pl.create_tensor([16, 16], dtype=pl.FP32)
                b_acc: pl.Tensor[[16, 16], pl.FP32] = pl.create_tensor([16, 16], dtype=pl.FP32)
                # Tuple call BEFORE the loop — makes _tuple_tmp/a_acc/b_acc loop-carried
                a_acc, b_acc = self.kernel_init(a_acc, b_acc)
                for i in pl.range(4):
                    # Tuple call INSIDE the loop — triggers iter_arg self-assignment
                    a_acc, b_acc = self.kernel_update(x, a_acc, b_acc)
                return a_acc

        generator = codegen.CCECodegen()
        files = generator.generate(TupleForLoopProgram)
        code = files["orchestration/orch_tuple_loop.cpp"]

        # No self-assignment in iter_arg init
        assert "auto _tuple_tmp = _tuple_tmp" not in code
        assert "auto a_acc = a_acc" not in code
        assert "auto b_acc = b_acc" not in code

        # No self-assignment in yield
        assert "_tuple_tmp = _tuple_tmp;" not in code
        assert "a_acc = a_acc;" not in code
        assert "b_acc = b_acc;" not in code

        # make_tensor declarations exist (exactly once each)
        # a_acc is a return value → external (make_tensor_external)
        assert code.count("Tensor ext_a_acc = make_tensor_external(") == 1
        assert code.count("Tensor b_acc = make_tensor(") == 1

        # For loop exists with correct structure
        assert "for (int64_t i = 0; i < 4; i += 1)" in code
        assert "PTO2_SCOPE(rt)" in code

        # Both tasks submitted
        assert "kernel_init" in code
        assert "kernel_update" in code
        assert code.count("pto2_rt_submit_task") == 2


if __name__ == "__main__":
    pytest.main([__file__, "-v"])
